{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from hloc import (\n",
    "    extract_features,\n",
    "    match_features,\n",
    "    reconstruction,\n",
    "    visualization,\n",
    "    pairs_from_retrieval,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In this notebook, we will run SfM reconstruction from scratch on a set of images. We choose the [South-Building dataset](https://openaccess.thecvf.com/content_cvpr_2013/html/Hane_Joint_3D_Scene_2013_CVPR_paper.html) - we will download it later. First, we define some paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Path(\"../data/train/dioscuri/\")  # change this if your dataset is somewhere else\n",
    "images = dataset / \"images/\"\n",
    "\n",
    "outputs = Path(\"outputs/sfm/\")\n",
    "sfm_pairs = outputs / \"pairs-dinov2.txt\"\n",
    "sfm_dir = outputs / \"sfm_superpoint+superglue\"\n",
    "\n",
    "retrieval_conf = extract_features.confs[\"dinov2_salad\"]\n",
    "feature_conf = extract_features.confs[\"xfeat\"]\n",
    "matcher_conf = match_features.confs[\"NN-xfeat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find image pairs via image retrieval\n",
    "We extract global descriptors with NetVLAD and find for each image the most similar ones. For smaller dataset we can instead use exhaustive matching via `hloc/pairs_from_exhaustive.py`, which would find $\\frac{n(n-1)}{2}$ images pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024/05/19 19:21:18 hloc INFO] Extracting local features with configuration:\n",
      "{'model': {'name': 'dinov2_salad'},\n",
      " 'output': 'global-feats-dinov2salad',\n",
      " 'preprocessing': {'resize_max': 1024}}\n",
      "[2024/05/19 19:21:18 hloc INFO] Found 70 images in root ../data/train/dioscuri/images.\n",
      "Using cache found in /home/salva/.cache/torch/hub/serizba_salad_main\n",
      "Using cache found in /home/salva/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/salva/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/salva/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/salva/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]/home/salva/.venv/image-matching/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 70/70 [00:02<00:00, 24.40it/s]\n",
      "[2024/05/19 19:21:27 hloc INFO] Finished exporting features.\n",
      "[2024/05/19 19:21:27 hloc INFO] Extracting image pairs from a retrieval database.\n",
      "[2024/05/19 19:21:28 hloc INFO] Found 350 pairs.\n"
     ]
    }
   ],
   "source": [
    "retrieval_path = extract_features.main(retrieval_conf, images, outputs)\n",
    "pairs_from_retrieval.main(retrieval_path, sfm_pairs, num_matched=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and match local features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024/05/19 19:21:58 hloc INFO] Extracting local features with configuration:\n",
      "{'model': {'name': 'xfeat', 'top_k': 4096},\n",
      " 'output': 'feats-xfeat',\n",
      " 'preprocessing': {'grayscale': False, 'resize_max': 1600}}\n",
      "[2024/05/19 19:21:58 hloc INFO] Found 70 images in root ../data/train/dioscuri/images.\n",
      "Using cache found in /home/salva/.cache/torch/hub/verlab_accelerated_features_main\n",
      "100%|██████████| 70/70 [00:03<00:00, 23.09it/s]\n",
      "[2024/05/19 19:22:02 hloc INFO] Finished exporting features.\n",
      "[2024/05/19 19:22:02 hloc INFO] Matching local features with configuration:\n",
      "{'model': {'name': 'cosine_mlp', 'top_k': 4096},\n",
      " 'output': 'matches-xfeat',\n",
      " 'preprocessing': {'grayscale': False, 'resize_max': 1600}}\n",
      "Using cache found in /home/salva/.cache/torch/hub/verlab_accelerated_features_main\n",
      "100%|██████████| 217/217 [00:02<00:00, 74.80it/s]\n",
      "[2024/05/19 19:22:05 hloc INFO] Finished exporting matches.\n"
     ]
    }
   ],
   "source": [
    "feature_path = extract_features.main(feature_conf, images, outputs)\n",
    "match_path = match_features.main(\n",
    "    matcher_conf, sfm_pairs, feature_conf[\"output\"], outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D reconstruction\n",
    "Run COLMAP on the features and matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024/05/19 19:22:14 hloc INFO] Creating an empty database...\n",
      "[2024/05/19 19:22:14 hloc INFO] Importing images into the database...\n",
      "[2024/05/19 19:22:15 hloc INFO] Importing features into the database...\n",
      "100%|█████████████████████████████████████████| 70/70 [00:00<00:00, 1523.75it/s]\n",
      "[2024/05/19 19:22:15 hloc INFO] Importing matches into the database...\n",
      "  0%|                                                   | 0/350 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 386 is out of bounds for axis 0 with size 386",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msfm_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msfm_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/image-matching/Hierarchical-Localization/hloc/reconstruction.py:132\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(sfm_dir, image_dir, pairs, features, matches, camera_mode, verbose, skip_geometric_verification, min_match_score, image_list, image_options, mapper_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m image_ids \u001b[38;5;241m=\u001b[39m get_image_ids(database)\n\u001b[1;32m    131\u001b[0m import_features(image_ids, database, features)\n\u001b[0;32m--> 132\u001b[0m \u001b[43mimport_matches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_match_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_geometric_verification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_geometric_verification:\n\u001b[1;32m    141\u001b[0m     estimation_and_geometric_verification(database, pairs, verbose)\n",
      "File \u001b[0;32m~/Workspace/image-matching/Hierarchical-Localization/hloc/triangulation.py:100\u001b[0m, in \u001b[0;36mimport_matches\u001b[0;34m(image_ids, database_path, pairs_path, matches_path, min_match_score, skip_geometric_verification)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m({(id0, id1), (id1, id0)} \u001b[38;5;241m&\u001b[39m matched) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m matches, scores \u001b[38;5;241m=\u001b[39m \u001b[43mget_matches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatches_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_match_score:\n\u001b[1;32m    102\u001b[0m     matches \u001b[38;5;241m=\u001b[39m matches[scores \u001b[38;5;241m>\u001b[39m min_match_score]\n",
      "File \u001b[0;32m~/Workspace/image-matching/Hierarchical-Localization/hloc/utils/io.py:79\u001b[0m, in \u001b[0;36mget_matches\u001b[0;34m(path, name0, name1)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reverse:\n\u001b[1;32m     78\u001b[0m     matches \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflip(matches, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m matches, scores\n",
      "\u001b[0;31mIndexError\u001b[0m: index 386 is out of bounds for axis 0 with size 386"
     ]
    }
   ],
   "source": [
    "model = reconstruction.main(sfm_dir, images, sfm_pairs, feature_path, match_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "We visualize some of the registered images, and color their keypoint by visibility, track length, or triangulated depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(model, images, color_by=\"visibility\", n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(model, images, color_by=\"track_length\", n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(model, images, color_by=\"depth\", n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
